<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Document</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      margin: 0px auto;
      width: 80%;
     
    }
    h1 {
      color: #403e3e; /* 제목 색상 변경 */
      border-bottom: 2px solid #ccc;
      padding-bottom: 10px;
      text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.5); /* 텍스트 그림자 추가 */
      font-size: 50px;
    }
    p {
      margin-bottom: 15px; /* 문단 간격 추가 */
      padding: 10px; /* 문단 패딩 추가 */
      background-color: rgba(255, 255, 255, 0.1); /* 문단 배경색 추가 */
      border-radius: 5px; /* 문단 모서리 둥글게 */
      font-size: 20px;
    }
    
  </style>
</head>
<body>
  <h1>뜻풀이</h1>
  <p>활성화 함수는 인공신경망에서 입력값을 출력값으로 <br>
    바꾸어서 전달해주는 신경망속 함수들을 의미</p>
  <h1>상세설명</h1>
<p>활성화 함수는 인공 신경망에서 각 뉴런의 출력을 결정하는 함수입니다. 입력값에 대한 비선형 변환을 수행하여 신경망이 복잡한 비선형 관계를 학습하고 모델링할 수 있게 합니다. 활성화 함수는 입력값을 받아 처리한 후 출력값을 생성합니다. <br>

  활성화 함수는 주로 뉴런의 출력값을 제한하고 비선형성을 추가함으로써 신경망이 다양한 함수를 학습할 수 있도록 도와줍니다.<br>
  
  일반적으로 다음과 같은 활성화 함수들이 사용됩니다.</p><br>
 
  <p>1. 시그모이드(Sigmoid) 함수: 시그모이드 함수는 S자 형태의 곡선을 가지며, 입력값을 0과 1 사이의 값으로 압축합니다. 주로 이진 분류 문제에서 출력층에서 사용될 수 있습니다. 그러나 기울기 소실 문제와 출력값의 폭이 제한되는 문제가 있어 깊은 신경망에서는 사용이 제한될 수 있습니다.<br>

  2. 하이퍼볼릭 탄젠트(Hyperbolic Tangent) 함수: 하이퍼볼릭 탄젠트 함수는 -1과 1 사이의 값을 출력하는 시그모이드 함수와 유사합니다. 하지만 출력 범위가 -1부터 1로 변경되었으며, 0을 중심으로 대칭적인 형태를 갖습니다.<br>
  
  3. 렐루(Rectified Linear Unit, ReLU) 함수: 렐루 함수는 입력이 0보다 작으면 0을 출력하고, 0보다 크면 입력값을 그대로 출력합니다. 계산이 간단하고 학습이 빠르게 진행되는 장점이 있어 가장 많이 사용되는 활성화 함수 중 하나입니다. 하지만 음수 입력에 대해서는 기울기가 0이 되는 문제가 있어 일부 뉴런이 "죽을 수" 있습니다. 이를 해결하기 위해 Leaky ReLU, Parametric ReLU 등의 변형된 버전도 있습니다.<br>

  4. 소프트맥스(Softmax) 함수: 소프트맥스 함수는 주로 다중 클래스 분류 문제에서 출력층에서 사용됩니다. 입력값을 각 클래스에 대한 확률로 변환하여 출력합니다. 소프트맥스 함수는 출력값의 총합이 1이 되도록 정규화되어 다중 클래스 확률 분포를 표현할 수 있습니다.<br>
 
  활성화 함수는 신경망의 학습과정에서 기울기 전파와 가중치 업데이트에 영향을 미칩니다. 따라서 활성화 함수의 선택은 신경망의 성능과 학습 속도에 영향을 줄 수 있습니다. 적절한 활성화 함수를 선택하는 것은 신경망 모델의 설계 과정에서 중요한 요소 중 하나입니다.</p>

</body>
</html>